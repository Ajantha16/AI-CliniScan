{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7ae7b6-85e8-4f85-a29b-1ccda3a3cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q albumentations==1.3.0 timm captum optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a945161e-d9f5-4758-b25f-a254413466b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "train_aug = A.Compose([\n",
    "    A.Resize(256,256),\n",
    "    A.RandomCrop(224,224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.GaussNoise(p=0.2),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    ToTensorV2()\n",
    "])\n",
    "val_aug = A.Compose([A.Resize(224,224), ToTensorV2()])\n",
    "\n",
    "# Adapter dataset: apply albumentations on PIL images\n",
    "class AlbChestDataset(ChestXrayDataset):\n",
    "    def __init__(self, df, root_dir, alb_transform=None, label_col='label'):\n",
    "        super().__init__(df, root_dir, transform=None, label_col=label_col)\n",
    "        self.alb = alb_transform\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(self.root/f\"{row['image_id']}.png\").convert('RGB')\n",
    "        img_np = np.array(img)\n",
    "        if self.alb:\n",
    "            out = self.alb(image=img_np)\n",
    "            img = out['image'].float()/255.0\n",
    "            # normalize same as earlier\n",
    "            # Note: ToTensorV2 already returns CHW\n",
    "        label = self.label2idx.get(row[self.label_col], 0) if self.label_col in self.df.columns else 0\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f907e-6364-4939-9e05-1dbb70a71b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm, optuna\n",
    "def create_model(lr, dropout):\n",
    "    m = timm.create_model('tf_efficientnet_b0', pretrained=True, num_classes=num_classes)\n",
    "    if hasattr(m, 'classifier'):\n",
    "        m.classifier = nn.Sequential(nn.Dropout(dropout), nn.Linear(m.classifier.in_features, num_classes))\n",
    "    return m.to(device)\n",
    "\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n",
    "    drop = trial.suggest_uniform('dropout', 0.0, 0.5)\n",
    "    model = create_model(lr, drop)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # small training loop on subset for quick search\n",
    "    for epoch in range(1):\n",
    "        model.train()\n",
    "        for i,(xb,yb) in enumerate(train_loader):\n",
    "            xb,yb = xb.to(device), yb.to(device)\n",
    "            loss = nn.CrossEntropyLoss()(model(xb), yb)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            if i>20: break\n",
    "    # return val loss (quick eval)\n",
    "    model.eval(); vl=0; cnt=0\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in val_loader:\n",
    "            xb,yb = xb.to(device), yb.to(device)\n",
    "            vl += nn.CrossEntropyLoss()(model(xb), yb).item()\n",
    "            cnt += 1\n",
    "            if cnt>5: break\n",
    "    return vl/cnt\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=8)\n",
    "print(\"Best params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0666e20c-991a-4430-ab21-d93fe7354f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerGradCam, visualize_image_attr\n",
    "model.eval()\n",
    "layer_gc = LayerGradCam(model, model.layer4[-1])  \n",
    "img, label = val_ds[0]\n",
    "inp = img.unsqueeze(0).to(device)\n",
    "attr = layer_gc.attribute(inp, target=label.item())\n",
    "# upsample and display\n",
    "from captum.attr import LayerAttribution\n",
    "cam = LayerAttribution.interpolate(attr, img.shape[1:])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img.permute(1,2,0).cpu()); plt.imshow(cam.squeeze().cpu(), alpha=0.5)\n",
    "plt.title(\"Grad-CAM overlay\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07acf76f-6a13-4ca6-bc91-e1aba16015e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df4d19-310e-4616-8702-f8581238512b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f34b8b-1609-408f-8868-fc5929bc1d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c535a7-59ec-4b16-84d5-21385761c2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
